---
layout: default
title: Fuzzing
type: Homework
number: 02
active_tab: homework
release_date: 2024-02-11
due_date: 2024-02-18 23:59:00EDT

---

<!-- Check whether the assignment is ready to release -->
{% capture today %}{{'now' | date: '%s'}}{% endcapture %}
{% capture release_date %}{{page.release_date | date: '%s'}}{% endcapture %}
{% if release_date > today %} 
<div class="alert alert-danger">
Warning: this assignment is out of date.  It may still need to be updated for this year's class.  Check with your instructor before you start working on this assignment.
</div>
{% endif %}
<!-- End of check whether the assignment is up to date -->


<!-- Check whether the assignment is up to date -->
{% capture this_year %}{{'now' | date: '%Y'}}{% endcapture %}
{% capture due_year %}{{page.due_date | date: '%Y'}}{% endcapture %}
{% if this_year != due_year %} 
<div class="alert alert-danger">
Warning: this assignment is out of date.  It may still need to be updated for this year's class.  Check with your instructor before you start working on this assignment.
</div>
{% endif %}
<!-- End of check whether the assignment is up to date -->



{% if page.materials %}
<div class="alert alert-info">
You can download the materials for this assignment here:
<ul>
{% for item in page.materials %}
<li><a href="{{item.url}}">{{ item.name }}</a></li>
{% endfor %}
</ul>


<i>Remember to make a copy of the notebook into your own Drive by choosing “Save a Copy in Drive” from Colab’s “File” menu.</i>

</div>
{% endif %}





{{page.type}} {{page.number}}: {{page.title}}
=============================================================

_Due: {{page.due_date}}_

## Overview

In this assignment, you'll explore randomized testing for C and Java programs. We'll explore different randomized input strategies and measure their success. In class we discussed three "generations" of fuzzers. 

## Resources
1. [AFL++](https://aflplus.plus/)

## PART 1: Fuzzing with AFL

In this part of the assignment, you will use AFL++ to fuzz C programs. For parts one and two, you will be testing the target C programs in the `hw02/c_targets/` directory. 

First, to gain familiarity, take a look at each of the sample programs.

Let's start with the simplest program: `sanity1.c`

```C
int main() {
  char input[65536];
  fgets(input, sizeof(input), stdin);
  int x = 0;
  int y = 2;
  int z = y / x;
  return 0;
}
```

This program will crash with a divide-by-zero error regardless of what is supplied in stdin.

Try it out by running `./sanity1 <YOUR STD IN INPUT>` 

You should see a crash. Furthermore, when you run `ls` you should now see a `sanity1.cov` file. Code coverage is a measure of how much of a program’s code is executed in a particular run. There are a number of different criterias to describe coverage. In this assignment we are providing line and column coverage. You may notice that some locations are printed more than once. This is because coverage is calculated at the *instruction level*. For more information on instructions and how coverage is calculated, you can read this [LLVM primer](https://drive.google.com/file/d/1Vwdan96-bGiGsww4HYnqhW_fXycaOkvN/view). 

Inspect the rest of the target files. Try to come up with a crashing input and run them and inspect the coverage. 

Record the crashing inputs you manually derived, and report them in your `README.txt`.

> TODO FIX PATH{1,2,3} FILES so they don't have to come up with an input that's 140 length


The target programs `easy{n}.c`, and `path{n}.c`, are sample programs contrived for this assignment. We've also included `CVE-{year}-{n}.c` files. A CVE, or Common Vulnerabilities and Exposures, identifier is a unique reference number given to a publicly known cybersecurity vulnerability. The CVE identifier follows a specific format: **CVE-[Year]-[Number]**.

- **Year**: This part of the identifier indicates the year the vulnerability was discovered or made public. It reflects when the CVE ID was assigned, not necessarily when the vulnerability was found.
  
- **Number**: This is a sequential number assigned to the vulnerability within that year. The number typically starts from 1 and goes upwards as new vulnerabilities are identified throughout the year.

For example, in the identifier **CVE-2024-12345**:
- "2024" is the year the CVE was assigned.
- "12345" is the unique number of that vulnerability for the year 2024.

This system helps track and reference specific vulnerabilities in a standardized way. 

The CVE programs you will test are minimal code semgents inspired by the denotated real world vulnerability.

Now that you're familiar with the target programs and their bugs, let's use AFL to fuzz them. 


>> INSERT A DESCRIPTION OF AFL HERE (actually it might go better above this)... ALSO NEED A DESCRIPTION OF WHAT AFL++ IS


Measure median edge coverage over time?
Fuzzers usually do 24 hours but maybe have them do 1hour MAX.


Setup steps: [@eliz TODO: ask David to install on goldengate] https://github.com/AFLplusplus/AFLplusplus/blob/stable/docs/INSTALL.md

Record the time taken to find each bug.... 

Also record the crashing input. Is it different than the one you derived manually? Record your results in the README.

## Part 2: Building your own fuzzer

PART 2: Building your own fuzzer
    a) first gen - truly random
    b) second gen - mutating seed inputs
    c) third gen - feedback driven


1. Build a fuzzer
    a) truly random 
    b) feedback driven
2. Using AFL (AFL++)
    I guess just use the actual tool
    LibAFL is only in rust unfortunately...
3. Measure the difference?
    AFL++ is going to be faster just because we are reading in the C file.
4. Randoop?

HOW DO I GET THE COVERAGE? 
> do the instrumentation myself and have the target programs in the docker... Then, the only thing we need to do in the Java code is read from the file... 
        but lowkey that takes so long :/ That will be a good question.




## Part 3: API testing with Randoop

The difference between fuzzing and ...


## Part 4: Regression testing with EvoSuite

Did you find any bugs?
Explain why / why not. 

Run for 1min, 5min, and 10min.
Describe differnces in quality of tests.





Parts of this assignment were adapted from Mayur Naik's (my PhD advisor!) [software analysis course](https://software-analysis-class.org/). 


## Submitting

Submit the following files to the assignment called `HW02` on Gradescope:

1. `README.txt`
2. `Fuzzer.java`

